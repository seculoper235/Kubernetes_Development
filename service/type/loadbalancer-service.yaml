## LoadBalancer SERVICE ##
# 말 그대로 클라우드 서비스의 로드밸런서를 통해 서비스를 노출시키는 방식
# 외부 로드밸런서와 함께 동작하며, 노드 앞단에 위치하여 트래픽을 각 노드로 적절하게 분산시킨다
# 외부 또는 다른 노드에서 들어오는 요청을 로드밸런서 서비스가 받아 노드로 전달한다

## 동작 과정
### 생성 시
# 로드밸런서 서비스 생성
# 모든 노드에 랜덤한 포트 개방

### 요청을 받을 시
# 로드밸런서 서비스로 요청이 들어옴
# 적절히 분산시켜 특정 포트와 연결된 노드로 보냄
# 노드는 해당하는 파드로 요청을 전달

## 장점
# 서비스 생성과 동시에 모든 노드에 포트가 자동으로 열린다 -> NodePort와 달리 신경쓸 부분이 적음
# 서비스에다 요청을 보내기만 하면 됨 -> 서비스에서 알아서 각 노드로 트래픽을 분산시켜 줌
# 로드밸런서인 만큼 여러가지 분산 정책을 지원한다 -> Internal/External 트래픽 정책 등

## 단점
# 클라우드 환경에서만 사용할 수 있으며, 온프레미스에선 별도로 환경을 구축(오픈 스택 등)해야 사용할 수 있다

# 사용 케이스(사실 거의 대부분)
# 클라우드 로드밸런서가 존재하는 경우
# 다중 노드 환경일 경우

## External Traffic Policy
# Cluster(기본)
# 트래픽의 파드 균등 분산. 어떤 노드의 파드에게 전달하는 것인지 고려하지 않고, 파드의 개수만큼 1/n 하여 노드에 보낸다
# 균등한 트래픽을 보장하지만, Network Hop 추가로 인한 latency 문제가 발생할 수 있다
# (예를 들어 노드 A가 우선 요청을 받고 노드 B에 있는 파드 3에 전달하는 경우가 생긴다
# 이 경우 Client IP -> Dest IP가 아닌, Client IP -> Node_A IP, Node_A IP -> Dest IP의 과정을 한번 더 거치게 된다)

# Local
# 트래픽의 Node 분류 불균등 분산. Cluster와 달리 파드가 어떤 노드에 속하는지 확인한 후, 해당 노드에 보낸다
# 무조건 자신의 파드에게 전달하기에 Cluster 방식의 latency는 발생하지 않지만, 특정 노드에 트래픽이 몰릴 수 있는 문제가 발생할 수 있다
apiVersion: v1
kind: Service
metadata:
  name: loadbalancer-service
spec:
  selector:
    app: service-base-deployment-pod
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080

  type: LoadBalancer